{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ETL_Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvljMoU3vjY8UGl95yaqu8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cindym02/DiabeticData/blob/main/ETL_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HHA550_Diabetes Prediction Dataset\n",
        "\n",
        "\n",
        "\n",
        "## Healthcare-dataset-diabetes-data"
      ],
      "metadata": {
        "id": "ltZo0TerTWzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyforest\n",
        "import pandas as pd   # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np   # linear algebra\n",
        "import matplotlib.pyplot as plt  #graphs and plots\n",
        "import seaborn as sns   #data visualizations \n",
        "import csv # Some extra functionalities for csv  files - reading it as a dictionary\n",
        "from lightgbm import LGBMClassifier #sklearn is for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction \n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_validate   #break up dataset into train and test sets\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "\n",
        "# importing python library for working with missing data\n",
        "import missingno as msno\n",
        "# To install missingno use: !pip install missingno\n",
        "import re    # This library is used to perform regex pattern matching\n",
        "\n",
        "# import various functions from sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, classification_report, make_scorer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "import plotly \n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "from plotly.offline import iplot\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.figure_factory as ff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrFUuY7cS_9I",
        "outputId": "d95a4a1d-7665-4984-d23d-7d4fbab80cee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyforest\n",
            "  Downloading pyforest-1.1.0.tar.gz (15 kB)\n",
            "Building wheels for collected packages: pyforest\n",
            "  Building wheel for pyforest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyforest: filename=pyforest-1.1.0-py2.py3-none-any.whl size=14607 sha256=9688c10a7ffc39f6b183962913c339256dd7e3a6e7dca935d25680e17c3fb9d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1c/da/48e6c884142d485475d852d69d20a096aba5beceb338822893\n",
            "Successfully built pyforest\n",
            "Installing collected packages: pyforest\n",
            "Successfully installed pyforest-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "6-Bry6_TXwqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the CSV Data"
      ],
      "metadata": {
        "id": "W-l_5bNYX4VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diabetic_df = pd.read_csv('https://raw.githubusercontent.com/cindym02/DiabeticData/main/diabetic_data.csv')"
      ],
      "metadata": {
        "id": "FeBx1-jqXvLr"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}